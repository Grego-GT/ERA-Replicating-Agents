/**
 * FBI Director - Prompt Improvement System
 * 
 * The Director's job is to review and improve user prompts before they reach code generation.
 * This ensures prompts are clear, specific, and optimized for the best code output.
 * 
 * Strategy:
 * - Analyze user prompt for clarity and completeness
 * - Add context, examples, or constraints as needed
 * - Incorporate best practices for code generation
 * - Return an improved prompt that will yield better results
 */

import "jsr:@std/dotenv/load"; // needed for deno run; not req for smallweb or valtown
import { chat, type ChatMessage } from '../utils/wandb/index.ts';
import * as weave from '../utils/weave/index.ts';

// ============================================================================
// Type Definitions
// ============================================================================

/**
 * Options for prompt improvement
 */
export interface PromptImprovementOptions {
  /** Agent name (for context) */
  agentName?: string;
  /** System prompt to consider */
  systemPrompt?: string;
  /** Judging criteria to incorporate */
  judgingCriteria?: string;
  /** Target programming language */
  language?: string;
  /** Additional context or constraints */
  context?: string;
  /** Model to use for improvement */
  model?: string;
  /** Temperature for generation (lower = more focused) */
  temperature?: number;
  /** Previous attempt information (for refinement) */
  previousAttempt?: {
    prompt?: string;
    code?: string;
    executionOutput?: string;
    executionError?: string;
    errorType?: string;
  };
}

/**
 * Result of prompt improvement
 */
export interface PromptImprovementResult {
  /** Whether improvement was successful */
  success: boolean;
  /** Original user prompt */
  originalPrompt: string;
  /** Improved prompt */
  improvedPrompt: string;
  /** List of improvements made */
  improvements: string[];
  /** Analysis of the original prompt */
  analysis?: string;
  /** Recommendation for next iteration (chain of thought) */
  recommendation?: string;
  /** Error message if failed */
  error?: string;
  /** Model used */
  model?: string;
}

/**
 * Director's verdict on whether to continue iterating
 */
export interface DirectorVerdict {
  /** Whether the Director thinks we should retry */
  shouldRetry: boolean;
  /** Director's reasoning for the decision */
  reasoning: string;
  /** Key issues identified (if shouldRetry is true) */
  issues?: string[];
  /** Assessment of progress made */
  progressAssessment?: string;
}

/**
 * Agent description generated by Director
 */
export interface AgentDescriptionResult {
  /** Whether generation was successful */
  success: boolean;
  /** The generated description */
  description: string;
  /** Error message if failed */
  error?: string;
}

// ============================================================================
// System Prompts for Director
// ============================================================================

const DIRECTOR_DESCRIPTION_SYSTEM_PROMPT = `You are the FBI Director creating a concise, professional description of what an agent does.

Your mission: Analyze the agent's purpose and create a clear, helpful description.

## Guidelines:
- Be concise (1-2 sentences, max 200 characters)
- Focus on WHAT the agent does, not HOW it does it
- Use active voice and clear language
- Mention the key functionality or output
- Make it useful for someone browsing a list of agents

## Examples:
- "Calculates factorial of a number and returns the result"
- "Reverses strings and outputs them in reverse order"
- "Generates FizzBuzz sequence up to a specified number"
- "Sorts arrays using quicksort algorithm"
- "Fetches weather data from API and formats the response"

## Output Format:
You MUST respond with ONLY a JSON object (no markdown, no code blocks):

{
  "description": "Clear, concise description of what the agent does"
}

Keep it simple, clear, and useful.`;

const DIRECTOR_VERDICT_SYSTEM_PROMPT = `You are the FBI Director making a strategic verdict on whether to continue iterating or accept the current result.

Your mission: Analyze ALL previous attempts and their outcomes to decide if another iteration would be beneficial.

## What You'll Review:
- Original user prompt and intent
- All previous iterations with their:
  - Prompts used
  - Code generated
  - Execution results (success/failure)
  - Errors encountered
  - Progress made
  - Actual output (JSON or plain text)

## Assessing Execution Success:

### Compilation/Runtime Errors:
- If output contains TypeScript errors (TS), compilation failed ‚Üí Clear failure
- If output contains runtime exceptions ‚Üí Clear failure
- If output is null/empty ‚Üí Likely failure

### Successful Execution - Assess Output Intelligence:
You need to intelligently judge if the output meets the user's intent:

**If output is JSON:**
- Try to parse it
- Look for { "success": true/false } pattern if present
- Look for { "error": ... } patterns
- Check if data structure makes sense for the request

**If output is plain text:**
- Does it contain the expected result based on the user prompt?
- Examples:
  - Prompt: "reverse hello world" ‚Üí Output: "dlrow olleh" ‚úÖ Success
  - Prompt: "calculate factorial of 5" ‚Üí Output: "120" ‚úÖ Success
  - Prompt: "sum 1 to 100" ‚Üí Output: "5050" ‚úÖ Success
  - Prompt: "sort array" ‚Üí Output: "[1,2,3,4,5]" ‚úÖ Success
- Does it look like an error message? ‚Üí Failure
- Is it empty or null? ‚Üí Failure

### Use Your Intelligence:
Don't rely solely on structured formats. Read the output, understand the user's intent, and judge if the code accomplished the task.

## Decision Criteria:

### STOP Iterating (shouldRetry: false) if:
- ‚úÖ Code executed successfully AND output matches user's intent (JSON or plain text)
- ‚úÖ Output demonstrates correct result (even if format is different than expected)
- ‚ö†Ô∏è No progress in last 2 iterations (stuck in same error)
- ‚ö†Ô∏è Issue is not solvable through prompt refinement (environment/API limitation)
- ‚ö†Ô∏è Errors are becoming worse, not better

### CONTINUE Iterating (shouldRetry: true) if:
- ‚ùå Execution failed (compilation error, runtime error, or Daytona error)
- ‚ùå Output is empty, null, or clearly wrong for the user's request
- üìà Making progress (different errors or getting closer to correct output)
- üîß Clear path to fix the issue with better prompt
- üìä Haven't tried an obvious approach yet

## Output Format:
You MUST respond with ONLY a JSON object (no markdown, no code blocks):

{
  "shouldRetry": true or false,
  "reasoning": "Clear, decisive explanation of why you're making this decision based on output analysis",
  "issues": ["Issue 1", "Issue 2"],  // If shouldRetry is true
  "progressAssessment": "Brief assessment of what progress has been made across iterations"
}

Be 100% decisive - either we retry or we're done. No uncertainty. Make the call based on intelligent output assessment.`;

const DIRECTOR_SYSTEM_PROMPT = `You are the FBI Director - a senior strategist responsible for improving code generation prompts.

Your mission: Transform user prompts into optimized, detailed instructions that will produce the best possible code.

## Your Process:
1. **Analyze** the user's prompt for clarity, completeness, and specificity
2. **Review** previous attempts (if any) to understand what went wrong
3. **Identify** what's missing: context, constraints, examples, edge cases, output format
4. **Enhance** the prompt with:
   - Specific technical requirements
   - Code examples or patterns (if helpful)
   - Expected input/output behavior
   - Error handling requirements
   - Best practices to follow
   - Testing considerations

## When Refining After Errors:
If previous execution failed, focus on:
- **Compilation errors**: Add type definitions, imports, or syntax clarifications
- **Runtime errors**: Specify input validation, edge case handling, or logic fixes
- **Daytona errors**: Adjust output format, add proper error handling, or fix environment issues
- Learn from the previous code and errors to make specific improvements

## Guidelines:
- Preserve the user's core intent
- Add clarity without overcomplicating
- Include concrete examples when beneficial
- Specify output format (JSON, function signature, etc.)
- Consider edge cases and error handling
- Be specific about data types and structures
- Mention relevant patterns or best practices
- If refining, explicitly address previous errors

## Output Format:
You MUST respond with ONLY a JSON object (no markdown, no code blocks, just raw JSON):

{
  "improvedPrompt": "The enhanced prompt text here...",
  "improvements": [
    "Added specific output format requirement",
    "Included example input/output",
    "Specified error handling approach"
  ],
  "analysis": "Brief analysis of what was missing or what went wrong",
  "recommendation": "Strategic recommendation for the next iteration - what should the code generator focus on? This is your chain of thought for continuous improvement."
}

Remember: Your improved prompt should be clear, actionable, and optimized for generating high-quality code. The recommendation helps track your strategic thinking across iterations.`;

// ============================================================================
// Core Functions
// ============================================================================

/**
 * Improve a user prompt using AI
 * 
 * @param userPrompt - The original user prompt
 * @param options - Improvement options
 * @returns Improved prompt with analysis
 */
async function improvePrompt(
  userPrompt: string,
  options: PromptImprovementOptions = {}
): Promise<PromptImprovementResult> {
  const {
    agentName = 'unnamed-agent',
    systemPrompt,
    judgingCriteria,
    language = 'typescript',
    context,
    model = "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    temperature = 0.3, // Lower temperature for more focused improvements
    previousAttempt
  } = options;

  try {
    const isRefinement = !!previousAttempt;
    console.log(isRefinement ? 'üîÑ FBI Director refining prompt based on previous attempt...' : 'üéØ FBI Director analyzing prompt...');

    // Build the user message with all context
    let userMessage = `Original Prompt:\n${userPrompt}\n\n`;
    
    if (agentName !== 'unnamed-agent') {
      userMessage += `Agent Name: ${agentName}\n`;
    }
    
    userMessage += `Target Language: ${language}\n`;
    
    if (systemPrompt) {
      userMessage += `\nSystem Prompt Context:\n${systemPrompt}\n`;
    }
    
    if (judgingCriteria) {
      userMessage += `\nJudging Criteria:\n${judgingCriteria}\n`;
    }
    
    if (context) {
      userMessage += `\nAdditional Context:\n${context}\n`;
    }
    
    // Add previous attempt information for refinement
    if (previousAttempt) {
      userMessage += `\n## Previous Attempt (FAILED)\n`;
      
      if (previousAttempt.prompt) {
        userMessage += `\nPrevious Prompt Used:\n${previousAttempt.prompt}\n`;
      }
      
      if (previousAttempt.code) {
        userMessage += `\nPrevious Generated Code:\n\`\`\`${language}\n${previousAttempt.code}\n\`\`\`\n`;
      }
      
      if (previousAttempt.errorType) {
        userMessage += `\nError Type: ${previousAttempt.errorType}\n`;
      }
      
      if (previousAttempt.executionError) {
        userMessage += `\nExecution Error:\n${previousAttempt.executionError}\n`;
      }
      
      if (previousAttempt.executionOutput) {
        userMessage += `\nExecution Output:\n${previousAttempt.executionOutput}\n`;
      }
      
      userMessage += `\nPlease analyze what went wrong and provide an improved prompt that addresses these specific issues.`;
    } else {
      userMessage += `\nPlease analyze this prompt and provide an improved version that will generate better code.`;
    }

    // Call LLM to improve the prompt
    const messages: ChatMessage[] = [
      { role: 'user', content: userMessage }
    ];

    const response = await chat({
      model,
      messages,
      systemPrompt: DIRECTOR_SYSTEM_PROMPT,
      temperature,
      maxTokens: 2000
    });

    const content = response.choices[0].message.content;

    // Parse the JSON response
    let parsedResponse: {
      improvedPrompt: string;
      improvements: string[];
      analysis?: string;
      recommendation?: string;
    };

    try {
      // Try to extract JSON from the response
      // Sometimes models wrap JSON in markdown code blocks
      let jsonContent = content.trim();
      
      // Remove markdown code blocks if present
      if (jsonContent.startsWith('```')) {
        const match = jsonContent.match(/```(?:json)?\s*\n?([\s\S]*?)\n?```/);
        if (match) {
          jsonContent = match[1].trim();
        }
      }
      
      parsedResponse = JSON.parse(jsonContent);
    } catch (parseError) {
      console.warn('‚ö†Ô∏è Failed to parse Director response as JSON, using original prompt');
      console.warn('Raw response:', content);
      
      // Fallback: return original prompt if parsing fails
      return {
        success: false,
        originalPrompt: userPrompt,
        improvedPrompt: userPrompt,
        improvements: [],
        error: `Failed to parse Director response: ${parseError}`,
        model
      };
    }

    // Validate that we got required fields
    if (!parsedResponse.improvedPrompt || !Array.isArray(parsedResponse.improvements)) {
      console.warn('‚ö†Ô∏è Invalid Director response structure, using original prompt');
      return {
        success: false,
        originalPrompt: userPrompt,
        improvedPrompt: userPrompt,
        improvements: [],
        error: 'Invalid response structure from Director',
        model
      };
    }

    console.log(`‚úÖ FBI Director ${isRefinement ? 'refined' : 'improved'} prompt (${parsedResponse.improvements.length} improvements)`);
    if (parsedResponse.recommendation) {
      console.log(`üí° Recommendation: ${parsedResponse.recommendation.substring(0, 100)}...`);
    }

    return {
      success: true,
      originalPrompt: userPrompt,
      improvedPrompt: parsedResponse.improvedPrompt,
      improvements: parsedResponse.improvements,
      analysis: parsedResponse.analysis,
      recommendation: parsedResponse.recommendation,
      model
    };

  } catch (error) {
    const err = error as Error;
    console.error('‚ùå FBI Director failed:', err.message);
    
    // On error, return original prompt so workflow can continue
    return {
      success: false,
      originalPrompt: userPrompt,
      improvedPrompt: userPrompt, // Fallback to original
      improvements: [],
      error: err.message,
      model
    };
  }
}

/**
 * Export improvePrompt directly (tracing handled at orchestrator level)
 */
export const improvePromptWithAI = improvePrompt;

/**
 * Director makes a verdict on whether to continue iterating
 * Reviews ALL previous attempts and decides if another iteration is worthwhile
 * 
 * @param userPrompt - The original user prompt
 * @param allAttempts - Array of all previous generation attempts with execution results
 * @param options - Additional options
 * @returns Director's verdict on whether to retry
 */
async function makeVerdict(
  userPrompt: string,
  allAttempts: Array<{
    iteration: number;
    prompt: string;
    code: string;
    executionSuccess: boolean;
    executionOutput?: string;
    executionError?: string;
    errorType?: string;
  }>,
  options: {
    maxIterations: number;
    currentIteration: number;
    language?: string;
    model?: string;
  }
): Promise<DirectorVerdict> {
  const {
    maxIterations,
    currentIteration,
    language = 'typescript',
    model = "Qwen/Qwen3-Coder-480B-A35B-Instruct"
  } = options;

  try {
    console.log(`‚öñÔ∏è  FBI Director reviewing ${allAttempts.length} attempt(s) to make verdict...`);

    // Build comprehensive history message
    let userMessage = `Original User Prompt:\n${userPrompt}\n\n`;
    userMessage += `Language: ${language}\n`;
    userMessage += `Current Iteration: ${currentIteration}/${maxIterations}\n\n`;
    
    userMessage += `## Previous Attempts History:\n`;
    allAttempts.forEach((attempt) => {
      userMessage += `\n### Iteration ${attempt.iteration}:\n`;
      userMessage += `Prompt Used:\n${attempt.prompt.substring(0, 300)}...\n\n`;
      userMessage += `Code Generated (preview):\n\`\`\`${language}\n${attempt.code.substring(0, 400)}\n...\n\`\`\`\n\n`;
      userMessage += `Execution: ${attempt.executionSuccess ? '‚úÖ SUCCESS' : '‚ùå FAILED'}\n`;
      
      if (!attempt.executionSuccess) {
        if (attempt.errorType) {
          userMessage += `Error Type: ${attempt.errorType}\n`;
        }
        if (attempt.executionError) {
          userMessage += `Error:\n${attempt.executionError.substring(0, 500)}\n`;
        }
      }
      
      if (attempt.executionOutput) {
        userMessage += `Output (preview):\n${attempt.executionOutput.substring(0, 300)}\n`;
      }
    });
    
    userMessage += `\n## Your Task:\n`;
    userMessage += `Review all attempts and decide: Should we try another iteration, or should we stop here?\n`;
    userMessage += `Consider: progress made, error patterns, likelihood of success with another iteration.\n`;

    const messages: ChatMessage[] = [
      { role: 'user', content: userMessage }
    ];

    const response = await chat({
      model,
      messages,
      systemPrompt: DIRECTOR_VERDICT_SYSTEM_PROMPT,
      temperature: 0.2, // Lower for more consistent decisions
      maxTokens: 1000
    });

    const content = response.choices[0].message.content;

    // Parse JSON response
    let verdict: DirectorVerdict;
    try {
      let jsonContent = content.trim();
      
      // Remove markdown code blocks if present
      if (jsonContent.startsWith('```')) {
        const match = jsonContent.match(/```(?:json)?\s*\n?([\s\S]*?)\n?```/);
        if (match) {
          jsonContent = match[1].trim();
        }
      }
      
      const parsed = JSON.parse(jsonContent);
      verdict = {
        shouldRetry: parsed.shouldRetry,
        reasoning: parsed.reasoning,
        issues: parsed.issues,
        progressAssessment: parsed.progressAssessment
      };
    } catch (parseError) {
      console.warn('‚ö†Ô∏è  Failed to parse Director verdict, defaulting to retry');
      console.warn('Raw response:', content);
      
      // Default to retry if can't parse, but only if not at max iterations
      return {
        shouldRetry: currentIteration < maxIterations,
        reasoning: `Failed to parse verdict: ${parseError}. Defaulting to ${currentIteration < maxIterations ? 'retry' : 'stop'}.`
      };
    }

    // Validate verdict
    if (typeof verdict.shouldRetry !== 'boolean') {
      console.warn('‚ö†Ô∏è  Invalid verdict structure, defaulting to retry');
      return {
        shouldRetry: currentIteration < maxIterations,
        reasoning: 'Invalid verdict structure from Director'
      };
    }

    console.log(`‚öñÔ∏è  Director Verdict: ${verdict.shouldRetry ? 'üîÑ RETRY' : 'üõë STOP'}`);
    console.log(`   Reasoning: ${verdict.reasoning.substring(0, 150)}...`);

    return verdict;

  } catch (error) {
    const err = error as Error;
    console.error('‚ùå Director verdict failed:', err.message);
    
    // On error, default to retry unless at max iterations
    return {
      shouldRetry: currentIteration < maxIterations,
      reasoning: `Verdict failed with error: ${err.message}`
    };
  }
}

/**
 * Export makeVerdict directly (tracing handled at orchestrator level)
 */
export const getDirectorVerdict = makeVerdict;

/**
 * Generate a concise description of what the agent does
 * 
 * @param agentName - The name of the agent
 * @param userPrompt - The original user prompt
 * @param finalCode - The final generated code (optional, for context)
 * @returns Agent description result
 */
async function generateDescription(
  agentName: string,
  userPrompt: string,
  finalCode?: string
): Promise<AgentDescriptionResult> {
  try {
    console.log('üìù FBI Director generating agent description...');

    // Build the user message
    let userMessage = `Agent Name: ${agentName}\n`;
    userMessage += `Original Prompt: ${userPrompt}\n`;
    
    if (finalCode) {
      // Include a preview of the code for context
      const codePreview = finalCode.substring(0, 500);
      userMessage += `\nCode Preview:\n\`\`\`typescript\n${codePreview}\n...\n\`\`\`\n`;
    }
    
    userMessage += `\nGenerate a concise description of what this agent does.`;

    const messages: ChatMessage[] = [
      { role: 'user', content: userMessage }
    ];

    const response = await chat({
      model: "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      messages,
      systemPrompt: DIRECTOR_DESCRIPTION_SYSTEM_PROMPT,
      temperature: 0.3,
      maxTokens: 200
    });

    const content = response.choices[0].message.content;

    // Parse JSON response
    try {
      let jsonContent = content.trim();
      
      // Remove markdown code blocks if present
      if (jsonContent.startsWith('```')) {
        const match = jsonContent.match(/```(?:json)?\s*\n?([\s\S]*?)\n?```/);
        if (match) {
          jsonContent = match[1].trim();
        }
      }
      
      const parsed = JSON.parse(jsonContent);
      
      if (!parsed.description || typeof parsed.description !== 'string') {
        throw new Error('Invalid response structure');
      }

      console.log('‚úÖ Agent description generated');
      
      return {
        success: true,
        description: parsed.description
      };

    } catch (parseError) {
      console.warn('‚ö†Ô∏è  Failed to parse description, using fallback');
      
      // Fallback: create a simple description from the prompt
      const fallbackDescription = userPrompt.length > 150 
        ? userPrompt.substring(0, 147) + '...'
        : userPrompt;
      
      return {
        success: false,
        description: fallbackDescription,
        error: `Parse error: ${parseError}`
      };
    }

  } catch (error) {
    const err = error as Error;
    console.error('‚ùå Description generation failed:', err.message);
    
    // Fallback to prompt
    const fallbackDescription = userPrompt.length > 150 
      ? userPrompt.substring(0, 147) + '...'
      : userPrompt;
    
    return {
      success: false,
      description: fallbackDescription,
      error: err.message
    };
  }
}

/**
 * Export generateDescription directly
 */
export const generateAgentDescription = generateDescription;

// ============================================================================
// Convenience Functions
// ============================================================================

/**
 * Quick prompt improvement with defaults
 * 
 * @param userPrompt - The original prompt
 * @param language - Target language (default: typescript)
 * @returns Improved prompt result
 */
export async function quickImprove(
  userPrompt: string,
  language: string = 'typescript'
): Promise<PromptImprovementResult> {
  return await improvePromptWithAI(userPrompt, { language });
}

// ============================================================================
// Testing
// ============================================================================

/**
 * Test the prompt improvement system
 */
export async function testDirector(): Promise<void> {
  console.log('üöÄ Testing FBI Director Prompt Improvement...\n');
  
  // Initialize Weave for tracing
  console.log('üîç Initializing Weave tracing...');
  await weave.init();
  console.log('');

  const testPrompts = [
    {
      prompt: 'Create a factorial function',
      language: 'typescript'
    },
    {
      prompt: 'make a todo list',
      language: 'typescript'
    },
    {
      prompt: 'sort an array',
      language: 'python'
    }
  ];

  for (let i = 0; i < testPrompts.length; i++) {
    const test = testPrompts[i];
    console.log('\n' + '='.repeat(80));
    console.log(`üìã Test ${i + 1}/${testPrompts.length}: "${test.prompt}" (${test.language})`);
    console.log('='.repeat(80) + '\n');

    try {
      const result = await improvePromptWithAI(test.prompt, {
        language: test.language,
        agentName: `test-agent-${i + 1}`
      });

      console.log('\nüìä RESULT:');
      console.log('---');
      console.log(`Success: ${result.success}`);
      console.log(`Model: ${result.model}`);
      
      if (result.success) {
        console.log(`\nüìù Original Prompt (${result.originalPrompt.length} chars):`);
        console.log(result.originalPrompt);
        
        console.log(`\n‚ú® Improved Prompt (${result.improvedPrompt.length} chars):`);
        console.log(result.improvedPrompt);
        
        if (result.analysis) {
          console.log('\nüîç Analysis:');
          console.log(result.analysis);
        }
        
        if (result.improvements.length > 0) {
          console.log('\nüéØ Improvements Applied:');
          result.improvements.forEach((imp, idx) => {
            console.log(`  ${idx + 1}. ${imp}`);
          });
        }
      } else {
        console.log(`\n‚ùå Error: ${result.error}`);
      }
      
      console.log('---\n');

    } catch (error) {
      const err = error as Error;
      console.error(`‚ùå Test failed: ${err.message}\n`);
    }
  }

  console.log('\n‚úÖ FBI Director tests complete!\n');
  console.log('üîç Check your Weave dashboard for traces: https://wandb.ai/\n');
}

// If run directly, execute tests
if (import.meta.main) {
  testDirector();
}

